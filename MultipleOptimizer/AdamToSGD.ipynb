{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from statistics import mean\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to .\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:08, 1147085.15it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\MNIST\\raw\\train-images-idx3-ubyte.gz to .\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to .\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 58034.02it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\MNIST\\raw\\train-labels-idx1-ubyte.gz to .\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to .\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:02, 718584.01it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to .\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to .\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 22122.69it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to .\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_set = MNIST('.', train=True, transform=transform, download=True)\n",
    "test_set = MNIST('.', train=False, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_set, batch_size=len(test_set), num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(128, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "adam = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "print_every = 400\n",
    "c = 0\n",
    "best_loss = 1e9\n",
    "train_losses = deque([], maxlen=print_every)\n",
    "train_accs = deque([], maxlen=print_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    'test_accs': [],\n",
    "    'test_losses': [],\n",
    "    'train_accs': [],\n",
    "    'train_losses': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001] (000/938) Trn loss: 2.29181 Tst loss: 2.28203 Trn acc: 0.14062 Tst acc: 0.11380\n",
      "[001] (400/938) Trn loss: 0.79403 Tst loss: 0.29588 Trn acc: 0.74223 Tst acc: 0.91660\n",
      "[001] (800/938) Trn loss: 0.46224 Tst loss: 0.24396 Trn acc: 0.86129 Tst acc: 0.92450\n",
      "[002] (262/938) Trn loss: 0.40439 Tst loss: 0.21838 Trn acc: 0.88070 Tst acc: 0.93290\n",
      "[002] (662/938) Trn loss: 0.37395 Tst loss: 0.20320 Trn acc: 0.88969 Tst acc: 0.93790\n",
      "[003] (124/938) Trn loss: 0.34651 Tst loss: 0.19861 Trn acc: 0.89676 Tst acc: 0.93850\n",
      "[003] (524/938) Trn loss: 0.32980 Tst loss: 0.18528 Trn acc: 0.90363 Tst acc: 0.94400\n",
      "[003] (924/938) Trn loss: 0.32681 Tst loss: 0.16970 Trn acc: 0.90363 Tst acc: 0.94840\n",
      "[004] (386/938) Trn loss: 0.29573 Tst loss: 0.16426 Trn acc: 0.91332 Tst acc: 0.94970\n",
      "[004] (786/938) Trn loss: 0.29387 Tst loss: 0.16176 Trn acc: 0.91266 Tst acc: 0.94890\n",
      "[005] (248/938) Trn loss: 0.28285 Tst loss: 0.14430 Trn acc: 0.91703 Tst acc: 0.95530\n",
      "[005] (648/938) Trn loss: 0.28035 Tst loss: 0.15156 Trn acc: 0.91633 Tst acc: 0.95450\n",
      "[006] (110/938) Trn loss: 0.28320 Tst loss: 0.14631 Trn acc: 0.91664 Tst acc: 0.95480\n",
      "[006] (510/938) Trn loss: 0.25674 Tst loss: 0.14761 Trn acc: 0.92211 Tst acc: 0.95420\n",
      "[006] (910/938) Trn loss: 0.27680 Tst loss: 0.15069 Trn acc: 0.91762 Tst acc: 0.95280\n",
      "[007] (372/938) Trn loss: 0.25882 Tst loss: 0.14266 Trn acc: 0.92215 Tst acc: 0.95660\n",
      "[007] (772/938) Trn loss: 0.25825 Tst loss: 0.14396 Trn acc: 0.92539 Tst acc: 0.95510\n",
      "[008] (234/938) Trn loss: 0.25564 Tst loss: 0.12896 Trn acc: 0.92473 Tst acc: 0.95970\n",
      "[008] (634/938) Trn loss: 0.25500 Tst loss: 0.12775 Trn acc: 0.92496 Tst acc: 0.96090\n",
      "[009] (096/938) Trn loss: 0.25467 Tst loss: 0.13452 Trn acc: 0.92590 Tst acc: 0.95930\n",
      "[009] (496/938) Trn loss: 0.24867 Tst loss: 0.13483 Trn acc: 0.92621 Tst acc: 0.95850\n",
      "[009] (896/938) Trn loss: 0.24449 Tst loss: 0.13304 Trn acc: 0.92566 Tst acc: 0.95970\n",
      "[010] (358/938) Trn loss: 0.23502 Tst loss: 0.12199 Trn acc: 0.92984 Tst acc: 0.96250\n",
      "[010] (758/938) Trn loss: 0.24040 Tst loss: 0.12467 Trn acc: 0.93035 Tst acc: 0.96240\n",
      "[011] (220/938) Trn loss: 0.23570 Tst loss: 0.11599 Trn acc: 0.93059 Tst acc: 0.96510\n",
      "[011] (620/938) Trn loss: 0.23161 Tst loss: 0.12480 Trn acc: 0.93129 Tst acc: 0.96100\n",
      "[012] (082/938) Trn loss: 0.22953 Tst loss: 0.11466 Trn acc: 0.93215 Tst acc: 0.96420\n",
      "[012] (482/938) Trn loss: 0.22497 Tst loss: 0.11224 Trn acc: 0.93367 Tst acc: 0.96540\n",
      "[012] (882/938) Trn loss: 0.22685 Tst loss: 0.11458 Trn acc: 0.93063 Tst acc: 0.96400\n",
      "[013] (344/938) Trn loss: 0.22562 Tst loss: 0.12761 Trn acc: 0.93379 Tst acc: 0.96150\n",
      "[013] (744/938) Trn loss: 0.22226 Tst loss: 0.11030 Trn acc: 0.93465 Tst acc: 0.96660\n",
      "[014] (206/938) Trn loss: 0.22667 Tst loss: 0.12127 Trn acc: 0.93309 Tst acc: 0.96240\n",
      "[014] (606/938) Trn loss: 0.20965 Tst loss: 0.12163 Trn acc: 0.93660 Tst acc: 0.96210\n",
      "[015] (068/938) Trn loss: 0.22873 Tst loss: 0.11263 Trn acc: 0.93137 Tst acc: 0.96410\n",
      "[015] (468/938) Trn loss: 0.21746 Tst loss: 0.10915 Trn acc: 0.93707 Tst acc: 0.96740\n",
      "[015] (868/938) Trn loss: 0.22465 Tst loss: 0.11148 Trn acc: 0.93215 Tst acc: 0.96570\n",
      "[016] (330/938) Trn loss: 0.20582 Tst loss: 0.10582 Trn acc: 0.93750 Tst acc: 0.96730\n",
      "[016] (730/938) Trn loss: 0.19744 Tst loss: 0.10464 Trn acc: 0.94355 Tst acc: 0.96820\n",
      "[017] (192/938) Trn loss: 0.19237 Tst loss: 0.10391 Trn acc: 0.94332 Tst acc: 0.96860\n",
      "[017] (592/938) Trn loss: 0.18572 Tst loss: 0.10349 Trn acc: 0.94508 Tst acc: 0.96890\n",
      "[018] (054/938) Trn loss: 0.18474 Tst loss: 0.10267 Trn acc: 0.94570 Tst acc: 0.96950\n",
      "[018] (454/938) Trn loss: 0.17180 Tst loss: 0.10248 Trn acc: 0.94699 Tst acc: 0.96900\n",
      "[018] (854/938) Trn loss: 0.18355 Tst loss: 0.10196 Trn acc: 0.94449 Tst acc: 0.96930\n",
      "[019] (316/938) Trn loss: 0.18023 Tst loss: 0.10165 Trn acc: 0.94711 Tst acc: 0.96940\n",
      "[019] (716/938) Trn loss: 0.18145 Tst loss: 0.10133 Trn acc: 0.94633 Tst acc: 0.96930\n",
      "[020] (178/938) Trn loss: 0.17329 Tst loss: 0.10095 Trn acc: 0.94945 Tst acc: 0.96950\n",
      "[020] (578/938) Trn loss: 0.18589 Tst loss: 0.10074 Trn acc: 0.94508 Tst acc: 0.96960\n",
      "[021] (040/938) Trn loss: 0.17387 Tst loss: 0.10052 Trn acc: 0.94824 Tst acc: 0.96990\n",
      "[021] (440/938) Trn loss: 0.17207 Tst loss: 0.10048 Trn acc: 0.94922 Tst acc: 0.96980\n",
      "[021] (840/938) Trn loss: 0.16963 Tst loss: 0.10020 Trn acc: 0.95000 Tst acc: 0.96990\n",
      "[022] (302/938) Trn loss: 0.16776 Tst loss: 0.10016 Trn acc: 0.95109 Tst acc: 0.97000\n",
      "[022] (702/938) Trn loss: 0.16916 Tst loss: 0.09974 Trn acc: 0.94969 Tst acc: 0.97000\n",
      "[023] (164/938) Trn loss: 0.16910 Tst loss: 0.09981 Trn acc: 0.94957 Tst acc: 0.97010\n",
      "[023] (564/938) Trn loss: 0.16617 Tst loss: 0.09975 Trn acc: 0.95039 Tst acc: 0.96970\n",
      "[024] (026/938) Trn loss: 0.16602 Tst loss: 0.09941 Trn acc: 0.95164 Tst acc: 0.97000\n",
      "[024] (426/938) Trn loss: 0.16689 Tst loss: 0.09911 Trn acc: 0.95188 Tst acc: 0.96980\n",
      "[024] (826/938) Trn loss: 0.16821 Tst loss: 0.09909 Trn acc: 0.95203 Tst acc: 0.96990\n",
      "[025] (288/938) Trn loss: 0.16868 Tst loss: 0.09884 Trn acc: 0.94969 Tst acc: 0.96990\n",
      "[025] (688/938) Trn loss: 0.17090 Tst loss: 0.09880 Trn acc: 0.94984 Tst acc: 0.97000\n",
      "[026] (150/938) Trn loss: 0.16978 Tst loss: 0.09885 Trn acc: 0.94969 Tst acc: 0.97010\n",
      "[026] (550/938) Trn loss: 0.17168 Tst loss: 0.09897 Trn acc: 0.95023 Tst acc: 0.97010\n",
      "[027] (012/938) Trn loss: 0.15952 Tst loss: 0.09872 Trn acc: 0.95176 Tst acc: 0.96990\n",
      "[027] (412/938) Trn loss: 0.17139 Tst loss: 0.09855 Trn acc: 0.94969 Tst acc: 0.97000\n",
      "[027] (812/938) Trn loss: 0.16337 Tst loss: 0.09855 Trn acc: 0.95270 Tst acc: 0.97030\n",
      "[028] (274/938) Trn loss: 0.16068 Tst loss: 0.09835 Trn acc: 0.95422 Tst acc: 0.97050\n",
      "[028] (674/938) Trn loss: 0.16901 Tst loss: 0.09810 Trn acc: 0.95074 Tst acc: 0.97030\n",
      "[029] (136/938) Trn loss: 0.15925 Tst loss: 0.09806 Trn acc: 0.95293 Tst acc: 0.97050\n",
      "[029] (536/938) Trn loss: 0.16334 Tst loss: 0.09787 Trn acc: 0.95340 Tst acc: 0.97030\n",
      "[029] (936/938) Trn loss: 0.16482 Tst loss: 0.09805 Trn acc: 0.95184 Tst acc: 0.97070\n",
      "[030] (398/938) Trn loss: 0.16939 Tst loss: 0.09780 Trn acc: 0.95063 Tst acc: 0.97070\n",
      "[030] (798/938) Trn loss: 0.16034 Tst loss: 0.09776 Trn acc: 0.95188 Tst acc: 0.97070\n"
     ]
    }
   ],
   "source": [
    "for e in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.view(-1, 28 * 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        train_losses.append(loss.item())\n",
    "        acc = torch.mean((torch.argmax(output, dim=1) == labels).float())\n",
    "        train_accs.append(acc.item())\n",
    "\n",
    "        if e < 15:\n",
    "            adam.zero_grad()\n",
    "            loss.backward()\n",
    "            adam.step()\n",
    "        else:\n",
    "            sgd.zero_grad()\n",
    "            loss.backward()\n",
    "            sgd.step()\n",
    "\n",
    "        if (c % print_every) == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                images, labels = next(iter(test_loader))\n",
    "                images = images.view(-1, 28 * 28).to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                output = model(images)\n",
    "                test_loss = criterion(output, labels)\n",
    "                test_acc = torch.mean((torch.argmax(output, dim=1) == labels).float())\n",
    "\n",
    "            print(\n",
    "                '[%03d]' % (e+1),\n",
    "                '(%03d/%03d)' % (i, len(train_loader)),\n",
    "                'Trn loss: %.5f' % mean(train_losses),\n",
    "                'Tst loss: %.5f' % test_loss.item(),\n",
    "                'Trn acc: %.5f' % mean(train_accs),\n",
    "                'Tst acc: %.5f' % test_acc.item(),\n",
    "                )\n",
    "            \n",
    "            history['test_accs'].append(test_acc.item())\n",
    "            history['test_losses'].append(test_loss.item())\n",
    "            history['train_accs'].append(mean(train_accs))\n",
    "            history['train_losses'].append(mean(train_losses))\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
